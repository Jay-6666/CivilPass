import base64
import json
import os
import re
import time
from collections import defaultdict
from datetime import datetime
from io import BytesIO

import jinja2
import matplotlib.pyplot as plt
import networkx as nx
import openai
import oss2
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import torch
from dotenv import load_dotenv
from matplotlib import font_manager
from PIL import Image
from pyvis.network import Network
from streamlit.runtime.scriptrunner import get_script_run_ctx

# ç¯å¢ƒå˜é‡è¯»å–
load_dotenv()
ACCESS_KEY_ID = os.getenv("ACCESS_KEY_ID")
ACCESS_KEY_SECRET = os.getenv("ACCESS_KEY_SECRET")
BUCKET_NAME = os.getenv("BUCKET_NAME")
REGION = os.getenv("REGION")
API_KEY = os.getenv("API_KEY")
MODEL_NAME = os.getenv("MODEL_NAME", "qwen-vl-plus")
BASE_URL = os.getenv("BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
ENDPOINT = f"https://{BUCKET_NAME}.oss-{REGION}.aliyuncs.com"

# OSS åˆå§‹åŒ–
auth = oss2.Auth(ACCESS_KEY_ID, ACCESS_KEY_SECRET)
bucket = oss2.Bucket(auth, f"http://oss-{REGION}.aliyuncs.com", BUCKET_NAME)


# æ·»åŠ è®¾å¤‡æ£€æµ‹å‡½æ•°
def is_mobile():
    """é€šè¿‡æµè§ˆå™¨ User-Agent è‡ªåŠ¨æ£€æµ‹ç§»åŠ¨ç«¯è®¾å¤‡"""
    try:
        ctx = get_script_run_ctx()
        if ctx is None:
            return False
        user_agent = ctx.request.headers.get("User-Agent", "").lower()
        return any(keyword in user_agent for keyword in ["mobi", "android", "iphone"])
    except Exception:
        return False  # å¼‚å¸¸æ—¶é»˜è®¤è¿”å›éç§»åŠ¨ç«¯


# å¤œæ™šæ¨¡å¼
def set_dark_mode(dark: bool):
    if dark:
        st.markdown(
            """
            <style>
                body, .stApp {
                    background-color: #1E1F29;
                    color: #F0F0F0;
                }

                .css-1d391kg, .css-1v0mbdj, .css-1cypcdb {
                    background-color: #2B2D3C !important;
                    color: #F0F0F0 !important;
                    border-radius: 10px;
                    padding: 10px;
                    transition: all 0.3s ease-in-out;
                }

                .stButton>button {
                    background-color: #3C82F6 !important;
                    color: white !important;
                    border: none;
                    padding: 0.5rem 1rem;
                    border-radius: 5px;
                    transition: all 0.2s ease-in-out;
                }

                .stButton>button:hover {
                    background-color: #559DFF !important;
                    transform: scale(1.03);
                }

                .stTextInput>div>div>input, .stSelectbox>div>div>div {
                    background-color: #3C3F51 !important;
                    color: #FFFFFF !important;
                    border-radius: 5px;
                    border: 1px solid #5A5D78;
                    transition: all 0.2s ease-in-out;
                }

                .stRadio > div {
                    background-color: #2B2D3C !important;
                    padding: 0.5rem;
                    border-radius: 8px;
                }

                .css-qrbaxs, .css-1xarl3l {
                    color: #F0F0F0 !important;
                }

                ::-webkit-scrollbar {
                    width: 8px;
                }

                ::-webkit-scrollbar-track {
                    background: #1E1F29;
                }

                ::-webkit-scrollbar-thumb {
                    background: #4B4D62;
                    border-radius: 4px;
                }

                /* åŠ¨ç”»è¿‡æ¸¡ */
                .block-container {
                    animation: fadeSlideIn 0.5s ease-in-out;
                }

                @keyframes fadeSlideIn {
                    0% {
                        opacity: 0;
                        transform: translateY(20px);
                    }
                    100% {
                        opacity: 1;
                        transform: translateY(0);
                    }
                }

            </style>
        """,
            unsafe_allow_html=True,
        )


# æ¶ˆæ¯æ°”æ³¡ UI
def chat_message(message, is_user=True):
    avatar = "ğŸ§‘â€ğŸ’»" if is_user else "ğŸ¤–"
    alignment = "flex-end" if is_user else "flex-start"
    bg_color = "#0E76FD" if is_user else "#2E2E2E"
    text_color = "#FFFFFF" if is_user else "#DDDDDD"

    st.markdown(
        f"""
        <div style='display: flex; justify-content: {alignment}; margin: 10px 0;'>
            <div style='background-color: {bg_color}; color: {text_color}; padding: 10px 15px;
                        border-radius: 12px; max-width: 70%;'>
                <strong>{avatar}</strong> {message}
            </div>
        </div>
    """,
        unsafe_allow_html=True,
    )


# ç¼“å­˜ OSS å†…å®¹
@st.cache_data(show_spinner=False)
def get_cached_oss_object(key):
    try:
        return bucket.get_object(key).read()
    except Exception:
        return None


# ä¸Šä¼ æ–‡ä»¶
def upload_file_to_oss(file, category="public"):
    file_name = f"{category}/{int(time.time())}_{file.name}"
    ext = os.path.splitext(file.name)[-1].lower()
    content_type_map = {
        ".pdf": "application/pdf",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".mp4": "video/mp4",
    }
    headers = {"Content-Type": content_type_map.get(ext, "application/octet-stream")}
    try:
        bucket.put_object(file_name, file.getvalue(), headers=headers)
        return f"{ENDPOINT}/{file_name}"
    except Exception as e:
        st.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        return None


# åƒé—® API
def query_qwen_api(user_input, image_url=None):
    """è°ƒç”¨åƒé—® APIï¼Œè¦æ±‚ AI ç”¨è‡ªç„¶è¯­è¨€å›ç­” + è¿½åŠ  JSON æ ¼å¼çŸ¥è¯†å›¾è°±ï¼Œæ”¯æŒå›¾æ–‡è¾“å…¥"""
    client = openai.OpenAI(api_key=API_KEY, base_url=BASE_URL)

    # æ›´è‡ªç„¶çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆæ—  markdown / æ— åˆ—è¡¨ï¼‰
    system_prompt = """
ä½ æ˜¯å…¬åŠ¡å‘˜è€ƒè¯•é¢†åŸŸçš„ä¸“å®¶ï¼Œè¯·é’ˆå¯¹ç”¨æˆ·æå‡ºçš„é—®é¢˜ï¼Œåƒä¸“å®¶è®²è§£ä¸€æ ·ï¼Œç”¨è‡ªç„¶ã€è¿è´¯çš„è¯­è¨€è¿›è¡Œæ¸…æ™°è§£ç­”ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨è‡ªç„¶ä¹¦é¢è¯­è¨€ï¼Œé€»è¾‘é€šé¡ºã€è¯­è¨€ç®€æ´ï¼Œæ— éœ€ä½¿ç”¨ markdownã€æ ‡é¢˜ã€ç¼–å·æˆ–åˆ—è¡¨ç­‰æ ¼å¼ç¬¦å·ã€‚
2. å›ç­”å®Œæ¯•åï¼Œè¯·è¿½åŠ è¾“å‡ºä¸€ä¸ªç»“æ„æ¸…æ™°çš„â€œçŸ¥è¯†å›¾è°±â€æ•°æ®ï¼ˆä½¿ç”¨ JSON æ ¼å¼ï¼‰ã€‚

çŸ¥è¯†å›¾è°±æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š
```json
{
  "knowledge_graph": {
    "nodes": [
      {"id": 1, "label": "æ ¸å¿ƒæ¦‚å¿µ", "description": "...", "color": "#4CAF50"},
      {"id": 2, "label": "ç›¸å…³æ³•è§„", "description": "...", "shape": "diamond"}
    ],
    "edges": [
      {"from": 1, "to": 2, "relation": "ä¾æ®", "width": 2}
    ]
  }
}
è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¿”å›ã€‚ """

    # å…³é”®è¯åˆ¤æ–­å›¾å½¢æ¨ç†é¢˜ï¼Œè¿½åŠ å›¾å½¢ä¸“å±æç¤º
    graphic_keywords = ["å›¾å½¢", "è§„å¾‹", "è¾¹æ•°", "é¢œè‰²", "æ—‹è½¬", "å¯¹ç§°", "æ’åˆ—"]
    if any(kw in user_input for kw in graphic_keywords):
        system_prompt += """
    æœ¬é¢˜å±äºã€å›¾å½¢æ¨ç†ç±»ã€‘ï¼Œè¯·åœ¨æ„å»ºçŸ¥è¯†å›¾è°±æ—¶ï¼Œè€ƒè™‘å¦‚ä¸‹ç»´åº¦ï¼š

    èŠ‚ç‚¹åº”åŒ…æ‹¬ï¼šå›¾å½¢æ¨ç†ã€å½¢çŠ¶å˜åŒ–ã€é¢œè‰²è§„å¾‹ã€ä½ç½®æ’åˆ—ã€å¯¹ç§°æ€§ ç­‰

    è¾¹çš„å…³ç³»å»ºè®®ä½¿ç”¨ï¼šâ€œåŒ…å«â€â€œä½“ç°â€â€œéµå¾ªâ€â€œå˜åŒ–ä¸ºâ€ ç­‰æ¸…æ™°è¯­ä¹‰

    æ‰€æœ‰èŠ‚ç‚¹å°½é‡æœ‰è¯´æ˜å­—æ®µï¼ˆdescriptionï¼‰ï¼Œä¾¿äºç†è§£

    æ„å»ºä¸€ä¸ªç»“æ„ä¸¥è°¨ã€å†…å®¹å®Œæ•´çš„å›¾å½¢æ¨ç†çŸ¥è¯†å›¾è°±ã€‚ """

    try:
        # æ„å»ºæ¶ˆæ¯ç»“æ„
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": []},
        ]

        if user_input:
            messages[1]["content"].append({"type": "text", "text": user_input})
        if image_url:
            messages[1]["content"].append(
                {"type": "image_url", "image_url": {"url": image_url}}
            )

        # è°ƒç”¨åƒé—®æ¨¡å‹
        completion = client.chat.completions.create(model=MODEL_NAME, messages=messages)
        return completion.choices[0].message.content

    except Exception as e:
        return f"âŒ AI è§£æå¤±è´¥: {str(e)}"


import json
import re


# æ‹†åˆ†å›ç­”æ–‡æœ¬ å’Œ å›¾è°± JSON éƒ¨åˆ†
def split_answer_and_graph(raw_output):
    pattern = r"```json(.*?)```"
    match = re.search(pattern, raw_output, re.DOTALL)

    if match:
        json_block = match.group(1).strip()
        text_part = raw_output[: match.start()].strip()
        return text_part, json_block
    else:
        return raw_output.strip(), None


# è‡ªç„¶è¯­è¨€å›ç­”å±•ç¤ºç»„ä»¶ï¼ˆå¯æ»šåŠ¨ï¼‰
def show_answer_scrollable(answer):
    st.markdown(
        f"""
        <div style="max-height: 400px; overflow-y: auto; padding: 12px; border: 1px solid #ccc; background-color: #fdfdfd; border-radius: 6px;">
            <p style="line-height: 1.6; font-size: 16px;">{answer}</p>
        </div>
        """,
        unsafe_allow_html=True,
    )


import hanlp

hanlp_pipeline = hanlp.load("FINE_ELECTRA_SMALL_ZH")  # ä¸­æ–‡ NER æ¨¡å‹


def extract_knowledge_graph(answer):
    """
    è‹¥æ˜¯å›¾å½¢æ¨ç†ç±»é—®é¢˜ï¼Œæ„å»ºä¸“å±å›¾è°±ï¼›å¦åˆ™ä½¿ç”¨å®ä½“è¯†åˆ«æ„å»ºé€šç”¨å›¾è°±ã€‚
    """

    # Step 1ï¼šå°è¯•è§£æ AI è‡ªå¸¦çš„çŸ¥è¯†å›¾è°±
    try:
        pattern = r"```json(.*?)```"
        match = re.search(pattern, answer, re.DOTALL)
        if match:
            kg_data = json.loads(match.group(1).strip())
            return (
                kg_data["knowledge_graph"]["nodes"],
                kg_data["knowledge_graph"]["edges"],
            )
    except Exception as e:
        pass  # ä¸å±•ç¤º warningï¼Œäº¤ç»™åç»­è‡ªåŠ¨ç”Ÿæˆ

    # Step 2ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯å›¾å½¢æ¨ç†ç±»é—®é¢˜
    graphic_keywords = ["å›¾å½¢", "æ¨ç†", "å˜åŒ–", "é¢œè‰²", "è¾¹æ•°", "è§„å¾‹", "å¯¹ç§°", "æ—‹è½¬", "æ’åˆ—"]
    if any(kw in answer for kw in graphic_keywords):
        # Step 3ï¼šæ„å»ºå›¾å½¢æ¨ç†ä¸“ç”¨çŸ¥è¯†å›¾è°±
        nodes = [
            {
                "id": 1,
                "label": "å›¾å½¢æ¨ç†",
                "description": "é€šè¿‡å›¾å½¢è§„å¾‹æ¨æ–­ç»“æœ",
                "color": "#4CAF50",
                "shape": "star",
            },
            {
                "id": 2,
                "label": "å½¢çŠ¶å˜åŒ–",
                "description": "è¾¹æ•°/ç»“æ„çš„å˜åŒ–æ¨¡å¼",
                "color": "#03A9F4",
                "shape": "box",
            },
            {
                "id": 3,
                "label": "é¢œè‰²è§„å¾‹",
                "description": "é¢œè‰²è½®æ¢/é‡å¤/æ¸å˜",
                "color": "#FFC107",
                "shape": "triangle",
            },
            {
                "id": 4,
                "label": "ä½ç½®æ’åˆ—",
                "description": "å›¾å½¢åœ¨ç©ºé—´ä½ç½®çš„å˜åŒ–",
                "color": "#E91E63",
                "shape": "diamond",
            },
            {
                "id": 5,
                "label": "å¯¹ç§°æ€§",
                "description": "è½´å¯¹ç§°/ä¸­å¿ƒå¯¹ç§°ç­‰å½¢å¼",
                "color": "#9C27B0",
                "shape": "ellipse",
            },
        ]
        edges = [
            {"from": 1, "to": 2, "relation": "åŒ…å«"},
            {"from": 1, "to": 3, "relation": "åŒ…å«"},
            {"from": 1, "to": 4, "relation": "åŒ…å«"},
            {"from": 1, "to": 5, "relation": "åŒ…å«"},
        ]
        return nodes, edges

    # Step 4ï¼šéå›¾å½¢æ¨ç†é¢˜ï¼Œå›é€€ HanLP NER æ¨¡å¼
    ner_result = hanlp_pipeline(answer)
    entities = ner_result.get("ner/msra", [])
    if not entities:
        return [], []

    entity_types = {"PER": "äººç‰©", "ORG": "ç»„ç»‡", "LOC": "åœ°ç‚¹", "TIME": "æ—¶é—´"}
    shape_map = {"PER": "dot", "ORG": "box", "LOC": "triangle", "TIME": "ellipse"}
    color_map = {
        "PER": "#03a9f4",
        "ORG": "#4caf50",
        "LOC": "#ff9800",
        "TIME": "#ab47bc",
    }

    nodes = []
    node_id_map = {}
    for idx, (text, ent_type, start, end) in enumerate(entities):
        node_id = idx + 1
        nodes.append(
            {
                "id": node_id,
                "label": text,
                "description": f"{entity_types.get(ent_type, 'å®ä½“')}ï¼š{text}",
                "color": color_map.get(ent_type, "#9e9e9e"),
                "shape": shape_map.get(ent_type, "ellipse"),
                "group": ent_type,
                "size": 28,
            }
        )
        node_id_map[text] = node_id

    # ç®€å•å…±ç°å…³ç³»æ„å»º
    edges = []
    for i in range(len(nodes)):
        for j in range(i + 1, len(nodes)):
            edges.append(
                {
                    "from": nodes[i]["id"],
                    "to": nodes[j]["id"],
                    "relation": "å…±ç°",
                    "color": "#ccc",
                    "width": 1,
                }
            )

    return nodes, edges


from pyvis.network import Network


def generate_kg_html(nodes, edges):
    net = Network(height="550px", width="100%", bgcolor="#ffffff", font_color="#333")

    # é«˜çº§ç¾åŒ–è®¾ç½®
    net.set_options(
        """
    {
      "physics": {
        "barnesHut": {
          "gravitationalConstant": -2500,
          "centralGravity": 0.3,
          "springLength": 200,
          "springConstant": 0.04,
          "damping": 0.09
        }
      },
      "interaction": {
        "hover": true,
        "navigationButtons": true,
        "tooltipDelay": 200
      },
      "nodes": {
        "font": {"size": 16, "face": "arial"},
        "shadow": true
      },
      "edges": {
        "color": {"inherit": true},
        "smooth": true
      }
    }
    """
    )

    for node in nodes:
        net.add_node(
            n_id=node.get("id"),
            label=node.get("label"),
            title=node.get("description", "æ— è¯¦ç»†è¯´æ˜"),
            color=node.get("color", "#4CAF50"),
            shape=node.get("shape", "ellipse"),
            group=node.get("group", None),
            size=node.get("size", 25),
        )

    for edge in edges:
        net.add_edge(
            edge.get("from"),
            edge.get("to"),
            title=edge.get("relation", "å…³è”"),
            width=edge.get("width", 1),
            color=edge.get("color", "#aaa"),
            arrows="to" if edge.get("direction", False) else "",
        )

    return net.generate_html()


# æ™ºèƒ½é—®ç­”æ¨¡å—
def showLLMChatbot():
    st.title("ğŸ“ æ™ºèƒ½å…¬è€ƒåŠ©æ‰‹")
    st.caption("ğŸ“¢ è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæˆ–æ‰¹é˜…ç”³è®ºä½œæ–‡ï¼ŒAIå¸®ä½ æå®šï¼")
    st.markdown("---")

    tabs = st.tabs(["ğŸ¤– æ™ºèƒ½é—®ç­”", "ğŸ“ ç”³è®ºæ‰¹é˜…"])

    with tabs[0]:  # æ™ºèƒ½é—®ç­”
        show_normal_chat()

    with tabs[1]:  # ç”³è®ºæ‰¹é˜…
        show_essay_review()


def show_normal_chat():

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "current_input" not in st.session_state:
        st.session_state.current_input = ""
    if "editing_index" not in st.session_state:
        st.session_state.editing_index = -1

    # èŠå¤©è®°å½•å®¹å™¨
    chat_container = st.container()

    # è‡ªå®šä¹‰å“åº”å¼CSS
    st.markdown(
        """
    <style>
    /* åŸºç¡€å¸ƒå±€ */
    .main .block-container {
        padding-bottom: 180px !important;
    }

    /* æ¡Œé¢ç«¯å›ºå®šè¾“å…¥åŒºåŸŸ */
    @media (min-width: 768px) {
        div[data-testid="stHorizontalBlock"]:has(> div:last-child:has(button[kind="primary"])) {
            position: fixed !important;
            bottom: 30px;
            left: 2rem;
            right: 2rem;
            padding: 1rem;
            box-shadow: 0 -4px 12px rgba(0,0,0,0.1);
            border-radius: 12px;
            background: white;
            z-index: 999;
            border: 1px solid #eee;
        }
    }

    /* ç§»åŠ¨ç«¯å¸ƒå±€ä¼˜åŒ– */
    @media (max-width: 767px) {
        /* è°ƒæ•´èŠå¤©æ¶ˆæ¯é—´è· */
        .stChatMessage {
            padding: 0.5rem !important;
            margin: 0.5rem 0 !important;
        }

        /* è¾“å…¥åŒºåŸŸå…¨å®½æ˜¾ç¤º */
        div[data-testid="column"] {
            width: 100% !important;
            padding: 0 !important;
        }

        /* æŒ‰é’®è§¦æ§ä¼˜åŒ– */
        button {
            padding: 0.8rem !important;
            min-height: 3rem !important;
        }

        /* æ–‡æœ¬è¾“å…¥æ¡†ä¼˜åŒ– */
        .stTextInput input {
            font-size: 16px !important;  /* é˜²æ­¢iOSç¼©æ”¾ */
            padding: 12px !important;
        }

        /* æ–‡ä»¶ä¸Šä¼ å™¨ä¼˜åŒ– */
        .stFileUploader {
            margin-top: 0.5rem !important;
        }

        /* éšè—æ¡Œé¢ç«¯ç¼–è¾‘æŒ‰é’® */
        .mobile-edit-btn {
            display: block !important;
        }
        .desktop-edit-btn {
            display: none !important;
        }
    }

    /* é€šç”¨ä¼˜åŒ– */
    img {
        max-width: 100% !important;  /* å›¾ç‰‡å“åº”å¼ */
    }

    /* å¤åˆ¶æŒ‰é’®ä¼˜åŒ– */
    .stCodeBlock button {
        min-width: 36px !important;
        min-height: 36px !important;
    }
    <style>
    /* çŸ¥è¯†å›¾è°±å®¹å™¨ */
    .pyvis-network {
        border: 1px solid #eee !important;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }

    /* èŠ‚ç‚¹æ ·å¼ */
    .node {
        transition: all 0.3s ease !important;
    }
    .node:hover {
        filter: brightness(1.1);
        transform: scale(1.05);
    }

    /* ç§»åŠ¨ç«¯ä¼˜åŒ– */
    @media (max-width: 767px) {
        .pyvis-network {
            height: 300px !important;
        }
        .node-label {
            font-size: 12px !important;
        }
    }

    /* å±•å¼€é¢æ¿åŠ¨ç”» */
    .streamlit-expanderContent {
        animation: kgSlideIn 0.3s ease-out;
    }

    @keyframes kgSlideIn {
        0% { opacity: 0; transform: translateY(-10px); }
        100% { opacity: 1; transform: translateY(0); }
    }
    </style>
    """,
        unsafe_allow_html=True,
    )

    # æ˜¾ç¤ºèŠå¤©è®°å½•
    with chat_container:
        for index, message in enumerate(st.session_state.messages):
            role = message["role"]
            content = message["content"]
            image_url = message.get("image_url")

            # å“åº”å¼åˆ—å¸ƒå±€
            cols = st.columns([0.85, 0.15])
            with cols[0]:
                with st.chat_message(role):
                    if role == "assistant":
                        text_part, kg_json_str = split_answer_and_graph(content)
                        show_answer_scrollable(text_part)

                        if kg_json_str:
                            try:
                                kg_data = json.loads(kg_json_str)
                                nodes = kg_data["knowledge_graph"]["nodes"]
                                edges = kg_data["knowledge_graph"]["edges"]
                                st.markdown("### ğŸ“Š å…³è”çŸ¥è¯†å›¾è°±")
                                with st.expander("ç‚¹å‡»æ¢ç´¢çŸ¥è¯†ç‚¹å…³ç³»", expanded=False):
                                    kg_html = generate_kg_html(nodes, edges)
                                    components.html(kg_html, height=400)
                            except Exception as e:
                                st.warning("âŒ çŸ¥è¯†å›¾è°±ç»“æ„è§£æå¤±è´¥")

                    if image_url and role == "user":
                        st.image(image_url, caption="ğŸ–¼ å·²ä¸Šä¼ å›¾ç‰‡", use_container_width=True)

            # ç¼–è¾‘æŒ‰é’®
            if role == "user":
                with cols[1]:
                    btn_style = "mobile-edit-btn" if is_mobile() else "desktop-edit-btn"
                    if st.button(
                            "âœï¸",
                            key=f"edit_{index}",
                            help="ç¼–è¾‘æ­¤é—®é¢˜",
                            use_container_width=True,
                            type="secondary",
                    ):
                        st.session_state.current_input = content
                        st.session_state.editing_index = index

    # è¾“å…¥åŒºåŸŸå®¹å™¨
    input_container = st.container()
    with input_container:
        # å“åº”å¼åˆ—å¸ƒå±€
        col1, col2 = st.columns([2, 1]) if not is_mobile() else st.columns([1])

        with col1:
            info = st.text_input(
                "âœï¸ é—®é¢˜è¾“å…¥",
                placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                value=st.session_state.current_input,
                key="user_input",
                label_visibility="visible" if not is_mobile() else "collapsed",
            )

        # ç§»åŠ¨ç«¯ç‹¬ç«‹æ˜¾ç¤ºä¸Šä¼ æŒ‰é’®
        if is_mobile():
            with st.container():
                uploaded_file = st.file_uploader(
                    "ğŸ“· ä¸Šä¼ è¯•é¢˜å›¾ç‰‡", type=["jpg", "png", "jpeg"], key="mobile_uploader"
                )
        else:
            with col2:
                uploaded_file = st.file_uploader(
                    "ğŸ“· ä¸Šä¼ è¯•é¢˜å›¾ç‰‡", type=["jpg", "png", "jpeg"], key="desktop_uploader"
                )

        # æäº¤æŒ‰é’®
        submit = st.button("ğŸš€ è·å– AI ç­”æ¡ˆ", use_container_width=True, type="primary")

    # å›¾ç‰‡ä¸Šä¼ å¤„ç†
    image_url = None
    if uploaded_file:
        with st.spinner("ğŸ”„ æ­£åœ¨ä¸Šä¼ å›¾ç‰‡..."):
            image_url = upload_file_to_oss(uploaded_file, category="civilpass/images")
        if image_url:
            st.success("âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼")

    # å¤„ç†æäº¤é€»è¾‘
    if submit:
        if not info and not image_url:
            st.warning("âš ï¸ è¯·å¡«å†™é—®é¢˜æˆ–ä¸Šä¼ å›¾ç‰‡")
        else:
            # å¤„ç†ç¼–è¾‘æ¨¡å¼
            if st.session_state.editing_index != -1:
                del st.session_state.messages[st.session_state.editing_index:]
                st.session_state.editing_index = -1

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            user_content = info if info else "ï¼ˆä»…ä¸Šä¼ å›¾ç‰‡ï¼‰"
            user_message = {
                "role": "user",
                "content": user_content,
                "image_url": image_url,
            }
            st.session_state.messages.append(user_message)

            # è·å–AIå“åº”
            with st.spinner("ğŸ¤– AI è§£æä¸­..."):
                answer = query_qwen_api(user_content, image_url)

            # æ·»åŠ AIæ¶ˆæ¯
            ai_message = {"role": "assistant", "content": answer}
            st.session_state.messages.append(ai_message)

            # é‡ç½®è¾“å…¥çŠ¶æ€
            st.session_state.current_input = ""
            st.session_state.uploaded_file = None
            st.rerun()


# from PIL import Image
# import pdfplumber
# import docx
# from paddleocr import PaddleOCR
# import numpy as np

# # åˆå§‹åŒ–OCRï¼ˆæ”¾åœ¨æ–‡ä»¶å¼€å¤´ï¼‰
# ocr_model = PaddleOCR(
#     use_angle_cls=False,
#     lang='ch',
#     det_model_dir='./models/ch_PP-OCRv4_det_infer',  # æœ¬åœ°æ£€æµ‹æ¨¡å‹è·¯å¾„
#     rec_model_dir='./models/ch_PP-OCRv4_rec_infer'   # æœ¬åœ°è¯†åˆ«æ¨¡å‹è·¯å¾„
# )


def show_essay_review():
    st.subheader("âœï¸ ç”³è®ºä½œæ–‡æ‰¹é˜…")

    tabs = st.tabs(["ğŸ–Šï¸ è¾“å…¥æ–‡æœ¬", "ğŸ“„ ä¸Šä¼ å›¾ç‰‡/æ–‡ä»¶"])

    with tabs[0]:
        essay_text = st.text_area("è¯·è¾“å…¥ä½ çš„ç”³è®ºä½œæ–‡", height=300, placeholder="ç²˜è´´æˆ–è¾“å…¥å®Œæ•´çš„ä½œæ–‡...")

        if st.button("ğŸš€ æäº¤æ‰¹é˜…", key="submit_text"):
            process_essay(essay_text)

    with tabs[1]:
        uploaded_file = st.file_uploader("ä¸Šä¼ ç”³è®ºä½œæ–‡å›¾ç‰‡æˆ–æ–‡ä»¶", type=["jpg", "jpeg", "png", "pdf", "docx"])

        if uploaded_file:
            # âœ… æ–°å¢ï¼šå¦‚æœæ˜¯å›¾ç‰‡ï¼Œå…ˆå‹ç¼©å°ºå¯¸
            if uploaded_file.type.startswith("image/"):
                image = Image.open(uploaded_file)
                max_width = 1200
                if image.width > max_width:
                    ratio = max_width / image.width
                    new_size = (max_width, int(image.height * ratio))
                    image = image.resize(new_size)
                    # æŠŠå‹ç¼©åçš„å›¾ç‰‡å­˜å› uploaded_file å˜é‡
                    # è¿™é‡Œè¦ç”¨BytesIOå†è½¬æˆæ–‡ä»¶å¯¹è±¡
                    from io import BytesIO
                    buffered = BytesIO()
                    image.save(buffered, format="JPEG")
                    buffered.seek(0)
                    uploaded_file = buffered  # é‡æ–°èµ‹å€¼ï¼

            # ä¸‹é¢ç»§ç»­åŸæ¥çš„æå–æ–‡æœ¬æµç¨‹
            file_text = extract_text_from_file(uploaded_file)

            if file_text:
                st.success("âœ… æ–‡ä»¶è¯†åˆ«æˆåŠŸï¼Œå¯ä»¥è¿›è¡Œæ‰¹é˜…")
                st.text_area("ğŸ“‹ è¯†åˆ«åˆ°çš„æ–‡æœ¬ï¼ˆå¯ä¿®æ”¹åæ‰¹é˜…ï¼‰", value=file_text, height=300, key="recognized_text")

                if st.button("ğŸš€ æäº¤æ‰¹é˜…", key="submit_file"):
                    process_essay(file_text)
            else:
                st.error("âŒ æ–‡ä»¶è¯†åˆ«å¤±è´¥ï¼Œè¯·ä¸Šä¼ æ¸…æ™°çš„å›¾ç‰‡æˆ–æ ‡å‡†æ–‡æ¡£")


def extract_text_from_file(file):
    file_type = file.type

    try:
        if "image" in file_type:
            # å›¾ç‰‡æ–‡ä»¶
            image = Image.open(file)
            result = ocr_model.ocr(np.array(image), cls=True)
            text = "\n".join([line[1][0] for line in result[0]])
            return text

        elif "pdf" in file_type:
            # PDFæ–‡ä»¶
            with pdfplumber.open(file) as pdf:
                pages = [page.extract_text() for page in pdf.pages]
            return "\n".join(pages)

        elif "officedocument" in file_type:
            # Word æ–‡ä»¶ (docx)
            doc = docx.Document(file)
            return "\n".join([p.text for p in doc.paragraphs])

        else:
            return None
    except Exception as e:
        st.error(f"è¯†åˆ«å‡ºé”™: {e}")
        return None


def process_essay(text):
    if not text.strip():
        st.warning("âš ï¸ å†…å®¹ä¸ºç©º")
        return

    with st.spinner("ğŸ§  æ­£åœ¨æ‰¹é˜…å¹¶ä¼˜åŒ–ä¸­ï¼Œè¯·ç¨å€™..."):
        history = improve_until_pass(text, target_score=90, max_rounds=5)

    if history:
        final = history[-1]

        st.success(f"âœ… ä¼˜åŒ–å®Œæˆï¼æœ€ç»ˆå¾—åˆ†ï¼š{final['total_score']} åˆ†")

        st.info("ğŸ”„ ä»¥ä¸‹ä¸ºè‡ªåŠ¨ä¼˜åŒ–åçš„æœ€ç»ˆæœ€ä¼˜ç‰ˆä½œæ–‡ï¼š")

        st.markdown("### ğŸ“œ ä¼˜åŒ–åä½œæ–‡")
        st.markdown(final['essay'])

        st.markdown("### ğŸ“Š å¾—åˆ†ç»´åº¦ï¼ˆç»†åˆ†é¡¹ï¼‰")
        if final['scores']:
            st.bar_chart(final['scores'])
        else:
            st.warning("âš ï¸ æœ€ç»ˆæœªèƒ½æˆåŠŸæå–æ¯ä¸ªç»´åº¦å¾—åˆ†ï¼Œè¯·æ£€æŸ¥æ‰¹é˜…æ ¼å¼")

        st.markdown("### ğŸ“‘ æ‰¹é˜…åé¦ˆè¯¦æƒ…")
        st.markdown(final['feedback'])


def improve_until_pass(initial_essay, target_score=90, max_rounds=1):
    """
    åªæ”¹è¿›ä¸€æ¬¡ç”³è®ºä½œæ–‡ï¼Œè¾¾æ ‡æˆ–ä¸è¾¾æ ‡éƒ½ç›´æ¥è¿”å›æœ€ç»ˆç»“æœã€‚
    """
    essay = initial_essay

    # ç¬¬ä¸€æ¬¡æ‰¹é˜…
    feedback = review_essay(essay)
    scores = extract_scores(feedback)
    total_score = sum(scores.values()) if scores else 0

    if total_score >= target_score:
        # å¦‚æœä¸€å¼€å§‹å°±è¾¾æ ‡ï¼Œç›´æ¥è¿”å›
        return [{
            "round": 1,
            "essay": essay,
            "feedback": feedback,
            "scores": scores,
            "total_score": total_score,
        }]
    else:
        # å¦‚æœæ²¡è¾¾æ ‡ï¼Œè¿›è¡Œä¸€æ¬¡ä¼˜åŒ–
        improved_essay = optimize_essay(essay, feedback)

        # å†æ¬¡æ‰¹é˜…ä¼˜åŒ–åçš„ä½œæ–‡
        feedback2 = review_essay(improved_essay)
        scores2 = extract_scores(feedback2)
        total_score2 = sum(scores2.values()) if scores2 else 0

        # è¿”å›ç¬¬ä¸€æ¬¡ä¼˜åŒ–åçš„æœ€ç»ˆç»“æœï¼ˆæ— è®ºæ˜¯å¦è¾¾æ ‡ï¼‰
        return [{
            "round": 1,
            "essay": improved_essay,
            "feedback": feedback2,
            "scores": scores2,
            "total_score": total_score2,
        }]


def review_essay(essay):
    client = openai.OpenAI(api_key=API_KEY, base_url=BASE_URL)

    system_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”³è®ºè€ƒè¯•æ‰¹é˜…ä¸“å®¶ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ‡å‡†ï¼ˆå„ç»´åº¦ç»†åˆ™ï¼‰å¯¹è€ƒç”Ÿä½œæ–‡è¿›è¡Œä¸¥æ ¼æ‰“åˆ†ã€‚æ¯ä¸ªå°é¡¹å¿…é¡»å•ç‹¬ç»™å‡ºå¾—åˆ†ã€‚
è¦æ±‚è¾“å‡ºæ ¼å¼æ ‡å‡†è§„èŒƒï¼Œæ–¹ä¾¿æå–ã€‚

ã€å†…å®¹ç»´åº¦ã€‘ï¼ˆ40åˆ†ï¼‰ï¼š
- åˆ‡é¢˜ç¨‹åº¦ï¼ˆ10åˆ†ï¼‰
- æ€æƒ³æ·±åº¦ï¼ˆ15åˆ†ï¼‰
- è®ºæ®è´¨é‡ï¼ˆ15åˆ†ï¼‰

ã€ç»“æ„ç»´åº¦ã€‘ï¼ˆ20åˆ†ï¼‰ï¼š
- æ•´ä½“å¸ƒå±€ï¼ˆ8åˆ†ï¼‰
- æ®µè½å®‰æ’ï¼ˆ6åˆ†ï¼‰
- å¼€å¤´ç»“å°¾ï¼ˆ6åˆ†ï¼‰

ã€è¯­è¨€ç»´åº¦ã€‘ï¼ˆ30åˆ†ï¼‰ï¼š
- è¯­è¨€è§„èŒƒï¼ˆ10åˆ†ï¼‰
- è¡¨è¾¾æµç•…ï¼ˆ10åˆ†ï¼‰
- é£æ ¼å¾—ä½“ï¼ˆ10åˆ†ï¼‰

ã€ä¹¦å†™ç»´åº¦ã€‘ï¼ˆ10åˆ†ï¼‰ï¼š
- å­—è¿¹å·¥æ•´ï¼ˆ4åˆ†ï¼‰
- å·é¢æ•´æ´ï¼ˆ3åˆ†ï¼‰
- å­—æ•°ç¬¦åˆï¼ˆ3åˆ†ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- æ¯ä¸ªå°é¡¹å¾—åˆ†æ¸…æ™°åˆ—å‡º
- æœ€åç»™å‡ºæ€»å¾—åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰
- å¿…é¡»ä¸¥æ ¼æ ¹æ®æ ‡å‡†ç»†åˆ™è¯„åˆ¤ï¼Œä¸è¦éšæ„æ»¡åˆ†ã€‚

ä¸‹é¢æ˜¯è€ƒç”Ÿä½œæ–‡ï¼Œè¯·è¿›è¡Œå…¨é¢æ‰¹é˜…å’Œæ‰“åˆ†ï¼š
"""

    user_prompt = f"{essay}"

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            stream=True  # âœ… å¼€å¯æµå¼è¾“å‡º
        )

        # Streamlitå®æ—¶å±•ç¤º
        collected_content = ""

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_message = ""

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    partial = chunk.choices[0].delta.content
                    full_message += partial
                    message_placeholder.markdown(full_message + "â–Œ")  # å®æ—¶åŠ¨æ€è¾“å‡º

            message_placeholder.markdown(full_message)  # æœ€ç»ˆè¡¥é½

        return full_message

    except Exception as e:
        return f"âŒ æ‰¹é˜…å¤±è´¥ï¼š{str(e)}"


def optimize_essay(essay, feedback):
    client = openai.OpenAI(api_key=API_KEY, base_url=BASE_URL)

    system_prompt = """
ä½ æ˜¯ä¸€åç”³è®ºå†™ä½œä¸“å®¶ï¼Œè¯·æ ¹æ®æ‰¹é˜…åé¦ˆå†…å®¹ï¼Œä¼˜åŒ–å’Œæå‡è€ƒç”Ÿä½œæ–‡ï¼Œä½¿å…¶å°½å¯èƒ½è¾¾åˆ°æ»¡åˆ†æ ‡å‡†ã€‚

è¦æ±‚ï¼š
- ä¿æŒåŸæ–‡ä¸»é¢˜ä¸å˜ã€‚
- é’ˆå¯¹æ‰¹é˜…åé¦ˆæŒ‡å‡ºçš„ä¸è¶³ï¼ˆå¦‚å†…å®¹æ·±åº¦ã€è®ºæ®è´¨é‡ã€ç»“æ„å®‰æ’ã€è¯­è¨€è§„èŒƒç­‰æ–¹é¢ï¼‰è¿›è¡Œæ”¹è¿›ã€‚
- ä¼˜åŒ–åçš„æ–‡ç« åº”æ›´ç¬¦åˆè¯„åˆ†æ ‡å‡†ï¼Œé¿å…åŸæœ‰é—®é¢˜ã€‚
- å­—æ•°ä¿æŒåˆç†ï¼Œè¯­è¨€ç¬¦åˆç”³è®ºæ–‡é£ã€‚

è¯·åªè¿”å›ä¼˜åŒ–åçš„å®Œæ•´ä½œæ–‡æ­£æ–‡ã€‚
"""

    user_prompt = f"""
ã€è€ƒç”ŸåŸæ–‡ã€‘ï¼š
{essay}

ã€æ‰¹é˜…åé¦ˆã€‘ï¼š
{feedback}

è¯·åœ¨ä»¥ä¸ŠåŸºç¡€ä¸Šè¿›è¡Œå…¨é¢ä¼˜åŒ–ã€‚
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            stream=True
        )

        collected_content = ""

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_message = ""

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    partial = chunk.choices[0].delta.content
                    full_message += partial
                    message_placeholder.markdown(full_message + "â–Œ")

            message_placeholder.markdown(full_message)

        return full_message

    except Exception as e:
        return f"âŒ ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}"


def extract_scores(feedback_text):
    """
    ä»æ‰¹é˜…åé¦ˆä¸­æå–ç»†é¡¹å¾—åˆ†ï¼Œå¢å¼ºç‰ˆï¼Œå…¼å®¹å„ç§å°å˜åŠ¨
    """
    import re

    small_items = [
        "åˆ‡é¢˜ç¨‹åº¦", "æ€æƒ³æ·±åº¦", "è®ºæ®è´¨é‡",
        "æ•´ä½“å¸ƒå±€", "æ®µè½å®‰æ’", "å¼€å¤´ç»“å°¾",
        "è¯­è¨€è§„èŒƒ", "è¡¨è¾¾æµç•…", "é£æ ¼å¾—ä½“",
        "å­—è¿¹å·¥æ•´", "å·é¢æ•´æ´", "å­—æ•°ç¬¦åˆ",
    ]

    extracted_scores = {}

    for item in small_items:
        # æ”¯æŒå¾—9åˆ†ï¼Œä¹Ÿæ”¯æŒç›´æ¥9åˆ†ï¼Œæ”¯æŒå„ç§å†’å·
        pattern = rf"{item}ï¼ˆ\d+åˆ†ï¼‰[:ï¼š]?\s*(?:å¾—)?(\d+)"
        match = re.search(pattern, feedback_text)
        if match:
            extracted_scores[item] = int(match.group(1))

    return extracted_scores if extracted_scores else None


# å¤‡è€ƒèµ„æ–™æ¨¡å—
def display_study_materials():
    st.title("ğŸ“š å¤‡è€ƒèµ„æ–™")
    st.caption("ğŸ“¢ æä¾›å„ç±»å¤‡è€ƒèµ„æ–™ï¼Œæ”¯æŒæŒ‰å¹´ä»½æœç´¢ã€åœ¨çº¿æŸ¥çœ‹å’Œä¸‹è½½ï¼")
    st.markdown("---")

    categories = ["è¡Œæµ‹", "ç”³è®º", "è§†é¢‘"]
    selected_categories = st.multiselect("ğŸ“‚ é€‰æ‹©ç±»åˆ«", categories)
    year_keyword = st.text_input("ğŸ” è¾“å…¥å¹´ä»½å…³é”®è¯ï¼ˆå¦‚ 2025ï¼‰")

    for category in selected_categories:
        st.subheader(f"ğŸ“ {category}")
        try:
            result = bucket.list_objects(prefix=category)
            if not result.object_list:
                st.warning(f"ğŸ“­ å½“å‰ç±»åˆ«æš‚æ— å†…å®¹")
                continue

            count = 0
            for obj in result.object_list:
                file_name = obj.key.split("/")[-1]
                file_url = f"{ENDPOINT}/{obj.key}"
                file_data = get_cached_oss_object(obj.key)

                if year_keyword and year_keyword not in file_name:
                    continue

                if category == "è§†é¢‘" and file_name.endswith((".mp4", ".webm")):
                    st.markdown(f"ğŸ¬ **{file_name}**")
                    st.video(file_url)
                elif file_name.endswith(".pdf"):
                    if not year_keyword and count >= 5:
                        continue
                    st.markdown(f"ğŸ“„ **{file_name}**")
                elif file_name.endswith((".jpg", ".jpeg", ".png")):
                    st.image(
                        BytesIO(file_data), caption=file_name, use_container_width=True
                    )

                st.markdown(f"[ğŸ“¥ ä¸‹è½½]({file_url})")
                st.markdown("---")
                count += 1
        except Exception as e:
            st.error(f"âŒ åŠ è½½å¤±è´¥ï¼š{e}")


# æ”¿ç­–èµ„è®¯æ¨¡å—
def display_policy_news():
    st.title("ğŸ“° æ”¿ç­–èµ„è®¯")
    st.caption("ğŸ“¢ æœ€æ–°å…¬åŠ¡å‘˜æ”¿ç­–åŠ¨æ€ä¸æƒå¨è§£è¯»")
    st.markdown("---")

    @st.cache_data(ttl=3600, show_spinner="æ­£åœ¨åŠ è½½æœ€æ–°æ”¿ç­–èµ„è®¯...")
    def load_all_policy_data():
        # é…ç½®å‚æ•°ï¼ˆå¯æå–åˆ°é…ç½®æ–‡ä»¶ï¼‰
        OSS_PATH = "æ”¿ç­–å’¨è¯¢"  # OSSå­˜å‚¨è·¯å¾„
        REQUIRED_COLUMNS = ["title", "source", "date", "url"]  # å¿…è¦å­—æ®µ
        DEFAULT_VALUES = {"summary": "æš‚æ— æ‘˜è¦", "region": "å…¨å›½", "hotness": 0}  # é»˜è®¤å€¼é…ç½®

        all_dfs = []
        error_files = []

        try:
            # è·å–ç›®å½•ä¸‹æ‰€æœ‰CSVæ–‡ä»¶
            files = bucket.list_objects(OSS_PATH).object_list
            csv_files = [f.key for f in files if f.key.endswith(".csv")]

            if not csv_files:
                st.error("âŒ ç›®å½•ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
                return pd.DataFrame()

            progress_text = f"æ­£åœ¨åŠ è½½ {len(csv_files)} ä¸ªæ•°æ®æº..."
            progress_bar = st.progress(0, text=progress_text)

            for i, file_path in enumerate(csv_files):
                try:
                    # è¯»å–CSVæ–‡ä»¶
                    csv_data = bucket.get_object(file_path).read()
                    df = pd.read_csv(
                        BytesIO(csv_data),
                        parse_dates=["date"],
                        usecols=REQUIRED_COLUMNS,
                    )

                    # å­—æ®µæ ¡éªŒ
                    missing_cols = set(REQUIRED_COLUMNS) - set(df.columns)
                    if missing_cols:
                        raise ValueError(f"ç¼ºå°‘å¿…è¦å­—æ®µï¼š{', '.join(missing_cols)}")

                    # æ·»åŠ æ•°æ®æºæ ‡è¯†
                    df["data_source"] = file_path.split("/")[-1]  # è®°å½•æ–‡ä»¶å

                    # è¡¥å……é»˜è®¤å€¼
                    for col, value in DEFAULT_VALUES.items():
                        df[col] = value

                    all_dfs.append(df)

                except Exception as e:
                    error_files.append((file_path, str(e)))
                finally:
                    progress_bar.progress((i + 1) / len(csv_files), text=progress_text)

            # åˆå¹¶æ•°æ®
            if not all_dfs:
                st.error("âŒ æ‰€æœ‰æ–‡ä»¶åŠ è½½å¤±è´¥")
                return pd.DataFrame()

            combined_df = pd.concat(all_dfs, ignore_index=True)

            # æ•°æ®æ¸…æ´—
            combined_df = (
                combined_df.dropna(subset=["title", "url"])
                .drop_duplicates("url", keep="first")
                .sort_values("date", ascending=False)
                .reset_index(drop=True)
            )

            return combined_df

        except Exception as e:
            st.error(f"âŒ ç›®å½•è®¿é—®å¤±è´¥ï¼š{str(e)}")
            return pd.DataFrame()
        finally:
            # æ˜¾ç¤ºåŠ è½½é”™è¯¯ä¿¡æ¯
            if error_files:
                with st.expander("âš ï¸ éƒ¨åˆ†æ–‡ä»¶åŠ è½½å¤±è´¥"):
                    for file, err in error_files:
                        st.markdown(f"`{file}`: {err}")

    df = load_all_policy_data()
    if df.empty:
        st.warning("âš ï¸ å½“å‰æ— å¯ç”¨æ”¿ç­–æ•°æ®")
        return

    if "current_page" not in st.session_state:
        st.session_state.current_page = 1

    with st.expander("ğŸ” æ™ºèƒ½ç­›é€‰", expanded=True):
        col1, col2 = st.columns([2, 3])
        with col1:
            date_range = st.date_input(
                "ğŸ“… æ—¥æœŸèŒƒå›´",
                value=(df["date"].min().date(), df["date"].max().date()),
                format="YYYY/MM/DD",
            )
            sources = st.multiselect(
                "ğŸ›ï¸ ä¿¡æ¯æ¥æº", options=df["source"].unique(), placeholder="å…¨éƒ¨æ¥æº"
            )
        with col2:
            keyword = st.text_input(
                "ğŸ” å…³é”®è¯æœç´¢", placeholder="æ ‡é¢˜/å†…å®¹å…³é”®è¯ï¼ˆæ”¯æŒç©ºæ ¼åˆ†éš”å¤šä¸ªå…³é”®è¯ï¼‰", help="ç¤ºä¾‹ï¼šå…¬åŠ¡å‘˜ å¾…é‡ è°ƒæ•´"
            )
            regions = st.multiselect(
                "ğŸŒ ç›¸å…³åœ°åŒº", options=df["region"].unique(), placeholder="å…¨å›½èŒƒå›´"
            )

    sort_col, _ = st.columns([1, 2])
    with sort_col:
        sort_option = st.selectbox(
            "æ’åºæ–¹å¼", options=["æœ€æ–°ä¼˜å…ˆ", "æœ€æ—§ä¼˜å…ˆ", "çƒ­åº¦æ’åº", "æ¥æºåˆ†ç±»"], index=0
        )

    def process_data(df):
        start_date = pd.Timestamp(date_range[0])
        end_date = pd.Timestamp(date_range[1])
        filtered = df[df["date"].between(start_date, end_date)]
        if sources:
            filtered = filtered[filtered["source"].isin(sources)]
        if regions:
            filtered = filtered[filtered["region"].isin(regions)]
        if keyword:
            keywords = [k.strip() for k in keyword.split()]
            pattern = "|".join(keywords)
            filtered = filtered[
                filtered["title"].str.contains(pattern, case=False)
                | filtered["summary"].str.contains(pattern, case=False)
                ]
        if sort_option == "æœ€æ–°ä¼˜å…ˆ":
            return filtered.sort_values("date", ascending=False)
        elif sort_option == "æœ€æ—§ä¼˜å…ˆ":
            return filtered.sort_values("date", ascending=True)
        elif sort_option == "çƒ­åº¦æ’åº":
            return filtered.sort_values("hotness", ascending=False)
        else:
            return filtered.sort_values(["source", "date"], ascending=[True, False])

    processed_df = process_data(df)

    PAGE_SIZE = 5
    total_items = len(processed_df)
    total_pages = max(1, (total_items + PAGE_SIZE - 1) // PAGE_SIZE)

    # ç¿»é¡µæŒ‰é’®
    col_prev, col_page, col_next = st.columns([1, 2, 1])
    with col_prev:
        if st.button("â† ä¸Šä¸€é¡µ") and st.session_state.current_page > 1:
            st.session_state.current_page -= 1
    with col_next:
        if st.button("ä¸‹ä¸€é¡µ â†’") and st.session_state.current_page < total_pages:
            st.session_state.current_page += 1
    with col_page:
        st.markdown(
            f"<div style='text-align: center; padding-top: 8px;'>ç¬¬ {st.session_state.current_page} é¡µ / å…± {total_pages} é¡µ</div>",
            unsafe_allow_html=True,
        )

    # é¡µç é‡ç½®é€»è¾‘
    if st.session_state.current_page > total_pages:
        st.session_state.current_page = total_pages

    start_idx = (st.session_state.current_page - 1) * PAGE_SIZE
    end_idx = start_idx + PAGE_SIZE
    current_data = processed_df.iloc[start_idx:end_idx]

    if current_data.empty:
        st.warning("ğŸ˜¢ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„èµ„è®¯")
    else:
        st.markdown(
            f"""
            <div style="background: #f0f2f6; padding: 12px; border-radius: 8px; margin: 10px 0;">
                ğŸ“Š æ‰¾åˆ° <strong>{len(processed_df)}</strong> æ¡ç»“æœ | 
                ğŸ“… æ—¶é—´è·¨åº¦ï¼š{date_range[0]} è‡³ {date_range[1]} | 
                ğŸŒŸ å¹³å‡çƒ­åº¦å€¼ï¼š{processed_df['hotness'].mean():.1f}
            </div>
        """,
            unsafe_allow_html=True,
        )

        for _, row in current_data.iterrows():
            with st.container(border=True):
                # å“åº”å¼åˆ—å¸ƒå±€
                col1, col2 = st.columns([4, 1], gap="small")

                with col1:
                    # å¢å¼ºå‹å¯ç‚¹å‡»æ ‡é¢˜
                    st.markdown(
                        f"""
                        <a href="{row['url']}" target="_blank" 
                            style="text-decoration: none;
                                   color: inherit;
                                   display: block;
                                   padding: 8px 0;">
                            <h3 style="margin: 0;
                                      font-size: 1.2rem;
                                      line-height: 1.4;
                                      border-bottom: 2px solid #eee;
                                      padding-bottom: 8px;">
                                {row['title']}
                            </h3>
                        </a>
                    """,
                        unsafe_allow_html=True,
                    )

                    meta_cols = st.columns([2, 2, 2], gap="small")
                    with meta_cols[0]:
                        st.markdown(f"ğŸ“… **æ—¥æœŸ**: {row['date'].strftime('%Y/%m/%d')}")
                    with meta_cols[1]:
                        st.markdown(f"ğŸ›ï¸ **æ¥æº**: {row['source']}")
                    with meta_cols[2]:
                        st.markdown(f"ğŸŒ **åœ°åŒº**: {row['region']}")
                    with st.expander("ğŸ“ æŸ¥çœ‹æ‘˜è¦"):
                        st.write(row["summary"])
                with col2:
                    st.markdown(
                        f"""
                        <div class="btn-group">
                            <div class="hotness-value">
                                ğŸ”¥ {row['hotness']}
                            </div>
                            <div class="btn-group-mobile">
                                <a href="{row['url']}" 
                                   target="_blank" 
                                   class="policy-btn btn-primary">
                                    ğŸ”— æŸ¥çœ‹åŸæ–‡
                                </a>
                                <button onclick="alert('æ”¶è—åŠŸèƒ½éœ€ç™»å½•åä½¿ç”¨')" 
                                        class="policy-btn btn-secondary">
                                    â­ æ”¶è—
                                </button>
                            </div>
                        </div>
                    """,
                        unsafe_allow_html=True,
                    )

    with st.expander("ğŸ“ˆ æ•°æ®æ´å¯Ÿ", expanded=False):
        tab1, tab2, tab3 = st.tabs(["æ¥æºåˆ†æ", "æ—¶é—´è¶‹åŠ¿", "åœ°åŒºåˆ†å¸ƒ"])

        with tab1:
            source_counts = processed_df["source"].value_counts().head(10)
            st.bar_chart(source_counts)

        with tab2:
            time_series = processed_df.set_index("date").resample("W").size()
            st.area_chart(time_series)

        with tab3:
            region_counts = processed_df["region"].value_counts()
            fig, ax = plt.subplots(figsize=(8, 8))
            plt.rcParams["font.sans-serif"] = ["SimHei"]
            plt.rcParams["axes.unicode_minus"] = False
            region_counts.plot.pie(autopct="%1.1f%%", ax=ax)
            ax.set_ylabel("")
            st.pyplot(fig)

        st.download_button(
            label="ğŸ“¥ å¯¼å‡ºå½“å‰ç»“æœï¼ˆCSVï¼‰",
            data=processed_df.to_csv(index=False).encode("utf-8"),
            file_name=f"policy_news_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            help="å¯¼å‡ºå½“å‰ç­›é€‰æ¡ä»¶ä¸‹çš„æ‰€æœ‰ç»“æœ",
        )

    # ç§»åŠ¨ç«¯ä¼˜åŒ–æ ·å¼
    st.markdown(
        """
        <style>
            /* é€šç”¨æŒ‰é’®æ ·å¼ */
            .policy-btn {
                display: block;
                width: 100%;
                padding: 8px;
                border-radius: 20px;
                text-decoration: none;
                text-align: center;
                transition: all 0.3s;
                margin: 6px 0;
                font-size: 0.9rem;
            }

            .hotness-value {
                font-size: 1.2rem; 
                color: #ff4b4b;
                margin: 8px 0;
                text-align: center;
            }

            /* æ¡Œé¢ç«¯ä¼˜åŒ– */
            @media (min-width: 769px) {
                .btn-group {
                    display: flex;
                    flex-direction: column;
                    gap: 8px;
                }
                .policy-btn {
                    padding: 8px 16px;
                }
            }

            /* ç§»åŠ¨ç«¯ä¼˜åŒ– */
            @media (max-width: 768px) {
                .btn-group-mobile {
                    display: flex;
                    flex-direction: column;
                    gap: 4px;
                }

                .policy-btn {
                    font-size: 0.85rem;
                    padding: 8px 12px;
                }

                .hotness-value {
                    font-size: 1rem !important;
                }

                /* ä¿æŒåŸæœ‰ç§»åŠ¨ç«¯ä¼˜åŒ– */
                .stContainer {
                    padding: 0 8px !important;
                }
                h3 {
                    font-size: 1.1rem !important;
                    line-height: 1.3 !important;
                }
                [data-testid="column"] {
                    padding: 4px !important;
                }
                a[target="_blank"] {
                    padding: 16px 0 !important;
                    margin: -16px 0 !important;
                    display: block !important;
                }
            }

            /* ä¸»é¢˜é…è‰² */
            .btn-primary {
                background: #007bff;
                color: white !important;
                border: 1px solid #007bff;
            }

            .btn-secondary {
                background: #28a745;
                color: white !important;
                border: 1px solid #28a745;
            }

            /* äº¤äº’æ•ˆæœ */
            .policy-btn:hover {
                opacity: 0.9;
                transform: translateY(-1px);
                box-shadow: 0 2px 6px rgba(0,0,0,0.1);
            }
            a:active, button:active {
                transform: scale(0.95) !important;
            }
        </style>
    """,
        unsafe_allow_html=True,
    )


# é«˜åˆ†ç»éªŒæ¨¡å—
def display_experience():
    st.title("ğŸŒŸ é«˜åˆ†ç»éªŒ")
    st.caption("ğŸ“¢ æ¥è‡ªé«˜åˆ†è€ƒç”Ÿçš„çœŸå®ç»éªŒåˆ†äº«")
    st.markdown("---")

    # ç”¨æˆ·ä¸Šä¼ åŠŸèƒ½åŒº
    with st.expander("ğŸ“¤ ä¸Šä¼ æˆ‘çš„å­¦ä¹ èµ„æ–™", expanded=False):
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col_upload, col_desc = st.columns([2, 3])

        with col_upload:
            upload_type = st.radio(
                "é€‰æ‹©ä¸Šä¼ ç±»å‹", ["å­¦ä¹ ç¬”è®°", "é”™é¢˜é›†"], horizontal=True, help="è¯·é€‰æ‹©èµ„æ–™åˆ†ç±»"
            )

            uploaded_files = st.file_uploader(
                "é€‰æ‹©æ–‡ä»¶",
                type=["pdf", "jpg", "jpeg", "png"],
                accept_multiple_files=True,
                help="æ”¯æŒæ ¼å¼ï¼šPDF/å›¾ç‰‡",
            )

            if st.button("ğŸš€ å¼€å§‹ä¸Šä¼ ", key="user_upload"):
                if not uploaded_files:
                    st.warning("è¯·å…ˆé€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶")
                    return

                success_count = 0
                target_folder = "å­¦ä¹ ç¬”è®°" if upload_type == "å­¦ä¹ ç¬”è®°" else "é”™é¢˜é›†"

                for file in uploaded_files:
                    # ç”Ÿæˆè§„èŒƒåŒ–æ–‡ä»¶åï¼šæ—¶é—´æˆ³_åŸå§‹æ–‡ä»¶å
                    timestamp = int(time.time())
                    safe_name = f"{timestamp}_{file.name.replace(' ', '_')}"
                    oss_path = f"{target_folder}/{safe_name}"

                    try:
                        bucket.put_object(oss_path, file.getvalue())
                        success_count += 1
                    except Exception as e:
                        st.error(f"'{file.name}' ä¸Šä¼ å¤±è´¥: {str(e)}")

                if success_count > 0:
                    st.success(f"æˆåŠŸä¸Šä¼  {success_count}/{len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼")
                    st.balloons()

        with col_desc:
            st.markdown(
                """
                **ğŸ“ ä¸Šä¼ è¯´æ˜**
                - æ–‡ä»¶å‘½åå»ºè®®ï¼š`ç§‘ç›®_å†…å®¹`ï¼ˆç¤ºä¾‹ï¼šè¡Œæµ‹_å›¾å½¢æ¨ç†æŠ€å·§.pdfï¼‰
                - å•ä¸ªæ–‡ä»¶å¤§å°é™åˆ¶ï¼šä¸è¶…è¿‡20MB
                - å®¡æ ¸æœºåˆ¶ï¼šä¸Šä¼ å†…å®¹å°†åœ¨24å°æ—¶å†…äººå·¥å®¡æ ¸
                - ç¦æ­¢ä¸Šä¼ åŒ…å«ä¸ªäººéšç§ä¿¡æ¯çš„èµ„æ–™
            """
            )

    # èµ„æ–™å±•ç¤ºåŠŸèƒ½åŒº
    st.markdown("## ğŸ“š èµ„æ–™æµè§ˆ")
    tab_exp, tab_notes, tab_errors = st.tabs(["ğŸ“œ é«˜åˆ†ç»éªŒ", "ğŸ“– å­¦ä¹ ç¬”è®°", "âŒ é”™é¢˜é›†"])

    # å…¬å…±æ˜¾ç¤ºå‡½æ•°
    def display_files(prefix, tab):
        try:
            file_list = []
            for obj in oss2.ObjectIterator(bucket, prefix=prefix):
                if not obj.key.endswith("/"):
                    # è§£ææ–‡ä»¶åï¼ˆå»é™¤æ—¶é—´æˆ³ï¼‰
                    raw_name = obj.key.split("/")[-1]
                    display_name = "_".join(raw_name.split("_")[1:])  # å»æ‰æ—¶é—´æˆ³

                    file_list.append(
                        {
                            "display": display_name,
                            "raw_name": raw_name,
                            "url": f"{ENDPOINT}/{obj.key}",
                            "type": "pdf"
                            if obj.key.lower().endswith(".pdf")
                            else "image",
                        }
                    )

            if not file_list:
                tab.warning("å½“å‰åˆ†ç±»ä¸‹æš‚æ— èµ„æ–™")
                return

            # ç½‘æ ¼å¸ƒå±€å±•ç¤º
            cols = tab.columns(3)
            for idx, file_info in enumerate(file_list):
                with cols[idx % 3]:
                    # æ–‡ä»¶é¢„è§ˆåŒºåŸŸ
                    with st.container(border=True):
                        # æ˜¾ç¤ºé¢„è§ˆ
                        if file_info["type"] == "image":
                            img_data = get_cached_oss_object(obj.key)
                            st.image(
                                BytesIO(img_data),
                                use_container_width=True,
                                caption=file_info["display"],
                            )
                        else:
                            # PDFæ˜¾ç¤ºå¸¦æ–‡ä»¶å
                            st.markdown(f"ğŸ“„ **{file_info['display']}**")
                            base64_pdf = base64.b64encode(
                                bucket.get_object(obj.key).read()
                            ).decode()
                            st.markdown(
                                f"""
                                <iframe 
                                    src="data:application/pdf;base64,{base64_pdf}"
                                    width="100%" 
                                    height="300px"
                                    style="border:1px solid #eee; border-radius:5px;">
                                </iframe>
                            """,
                                unsafe_allow_html=True,
                            )

                        # ä¸‹è½½æŒ‰é’®
                        st.markdown(
                            f"""
                            <div style="margin-top:10px; text-align:center;">
                                <a href="{file_info['url']}" download>
                                    <button style="
                                        background: #4CAF50;
                                        color: white;
                                        border: none;
                                        padding: 8px 20px;
                                        border-radius: 5px;
                                        cursor: pointer;">
                                        â¬‡ï¸ ä¸‹è½½
                                    </button>
                                </a>
                            </div>
                        """,
                            unsafe_allow_html=True,
                        )

        except Exception as e:
            tab.error(f"åŠ è½½å¤±è´¥ï¼š{str(e)}")

    # å„æ ‡ç­¾é¡µå†…å®¹
    with tab_exp:
        display_files(prefix="é«˜åˆ†ç»éªŒ/", tab=tab_exp)

    with tab_notes:
        display_files(prefix="å­¦ä¹ ç¬”è®°/", tab=tab_notes)

    with tab_errors:
        display_files(prefix="é”™é¢˜é›†/", tab=tab_errors)


# è€ƒè¯•æ—¥å†æ¨¡å—
def display_exam_calendar():
    st.title("ğŸ“… æ™ºèƒ½è€ƒè¯•æ—¥å†")
    st.markdown(
        "âš ï¸ <span style='color:red;'>è€ƒè¯•æ—¶é—´ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®˜æ–¹å…¬å¸ƒä¸ºå‡†ï¼</span>", unsafe_allow_html=True
    )
    st.markdown("---")

    # æ ·å¼æ³¨å…¥
    st.markdown(
        """
        <style>
            .timeline {
                border-left: 3px solid #3C82F6;
                padding-left: 20px;
                margin: 20px 0;
            }
            .timeline-item {
                margin: 15px 0;
                padding: 15px;
                background: #f5f7fb;
                border-radius: 8px;
                position: relative;
            }
            .timeline-date {
                font-weight: bold;
                color: #3C82F6;
                margin-bottom: 8px;
            }
            .timeline-content {
                margin-left: 25px;
            }
            .calendar-tag {
                display: inline-block;
                padding: 2px 8px;
                border-radius: 12px;
                background: #e6f0ff;
                color: #3C82F6;
                font-size: 0.8em;
                margin: 2px;
            }
            @media (max-width: 768px) {
                .timeline-item { padding: 10px; }
            }
        </style>
    """,
        unsafe_allow_html=True,
    )

    # ç¼“å­˜æ•°æ®åŠ è½½
    @st.cache_data(ttl=3600, show_spinner="æ­£åœ¨åŠ è½½è€ƒè¯•æ—¥å†...")
    def load_calendar_data():
        try:
            # åŠ è½½ç»“æ„åŒ–è€ƒè¯•äº‹ä»¶æ•°æ®
            event_file = bucket.get_object("è€ƒè¯•æ—¥å†/events_date.json").read()
            events = json.loads(event_file)["events"]

            # åŠ è½½å›¾ç‰‡æ–‡ä»¶ç´¢å¼•
            images = []
            for obj in oss2.ObjectIterator(bucket, prefix="è€ƒè¯•æ—¥å†/images/"):
                if obj.key.lower().endswith((".jpg", ".jpeg", ".png")):
                    images.append(
                        {
                            "key": obj.key,
                            "name": obj.key.split("/")[-1],
                            "url": f"{ENDPOINT}/{obj.key}",
                        }
                    )

            return {"events": sorted(events, key=lambda x: x["date"]), "images": images}

        except Exception as e:
            st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
            return {"events": [], "images": []}

    # åŠ è½½æ•°æ®
    data = load_calendar_data()
    events = data["events"]
    images = data["images"]

    # é¡¶éƒ¨è¿‡æ»¤æ 
    with st.container():
        col1, col2, col3 = st.columns([2, 3, 2])
        with col1:
            selected_year = st.selectbox(
                "é€‰æ‹©å¹´ä»½",
                options=sorted(
                    {datetime.strptime(e["date"], "%Y-%m-%d").year for e in events},
                    reverse=True,
                ),
                index=0,
            )
        with col2:
            search_query = st.text_input("ğŸ” æœç´¢è€ƒè¯•åç§°æˆ–åœ°åŒº", placeholder="è¾“å…¥å…³é”®è¯ç­›é€‰...")
        with col3:
            view_mode = "ğŸ—“ æœˆå†è§†å›¾"  # å¼ºåˆ¶å›ºå®šè§†å›¾æ¨¡å¼
            st.markdown(
                '<div style="visibility:hidden">å ä½</div>', unsafe_allow_html=True
            )

    # è¿‡æ»¤æ•°æ®
    filtered_events = [
        e
        for e in events
        if datetime.strptime(e["date"], "%Y-%m-%d").year == selected_year
           and (
                   search_query.lower() in e["name"].lower()
                   or any(search_query.lower() in r.lower() for r in e["regions"])
           )
    ]

    # å±•ç¤ºå†…å®¹
    if view_mode == "ğŸ—“ æœˆå†è§†å›¾":
        tabs = st.tabs([f"{m}æœˆ" for m in range(1, 13)])

        monthly_events = defaultdict(list)
        for event in filtered_events:
            month = datetime.strptime(event["date"], "%Y-%m-%d").month
            monthly_events[month].append(event)

        for idx, tab in enumerate(tabs):
            month_num = idx + 1
            with tab:
                # æŸ¥æ‰¾è¯¥æœˆå¯¹åº”å›¾ç‰‡
                month_images = [
                    img
                    for img in images
                    if f"{selected_year}-{month_num:02}" in img["name"]
                ]

                if month_images:
                    cols = st.columns(2)
                    for img_idx, img in enumerate(month_images):
                        with cols[img_idx % 2]:
                            with st.popover(f"ğŸ“· {img['name'].split('.')[0]}"):
                                img_data = get_cached_oss_object(img["key"])
                                st.image(BytesIO(img_data), use_container_width=True)
                                st.download_button(
                                    "ä¸‹è½½åŸå›¾",
                                    data=img_data,
                                    file_name=img["name"],
                                    mime="image/jpeg",
                                )
                            st.caption(f"ğŸ“… {img['name'].split('.')[0]}")

                # å±•ç¤ºäº‹ä»¶
                st.subheader(f"{month_num}æœˆé‡è¦è€ƒè¯•")
                if not monthly_events.get(month_num):
                    st.info("æœ¬æœˆæš‚æ— å·²å…¬å¸ƒçš„è€ƒè¯•å®‰æ’")
                    continue

                for event in monthly_events[month_num]:
                    with st.expander(f"ğŸ“Œ {event['name']} - {event['date']}"):
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.markdown(f"**æ—¥æœŸ**: {event['date']}")
                            st.markdown(f"**åœ°åŒº**: {', '.join(event['regions'])}")
                            st.markdown(f"**æ¥æº**: {', '.join(event['sources'])}")
                        with col2:
                            if event.get("image"):
                                st.image(f"{ENDPOINT}/{event['image']}", width=120)

    # ä¾§è¾¹æé†’æ 
    with st.sidebar:
        st.header("ğŸ”” æé†’æœåŠ¡")
        selected_events = st.multiselect(
            "é€‰æ‹©è¦æé†’çš„è€ƒè¯•",
            options=[e["name"] for e in filtered_events],
            placeholder="é€‰æ‹©è€ƒè¯•é¡¹ç›®",
        )

        if selected_events:
            remind_time = st.number_input("æå‰æé†’å¤©æ•°", min_value=1, max_value=30, value=7)
            if st.button("è®¾ç½®æé†’", type="primary"):
                st.toast("ğŸ‰ æé†’è®¾ç½®æˆåŠŸï¼å°†åœ¨è€ƒè¯•å‰{}å¤©é€šçŸ¥".format(remind_time))

        st.markdown("---")
        st.markdown("**ğŸ“² æ‰‹æœºè®¢é˜…**")
        st.write("æ‰«æäºŒç»´ç è®¢é˜…æ—¥å†")

        # è·å–äºŒç»´ç å›¾ç‰‡å¹¶å±•ç¤º
        try:
            qr_key = "civilpass/qrcode/exam_calendar_qrcode.png"
            qr_image_data = get_cached_oss_object(qr_key)

            if qr_image_data:
                import base64

                b64_img = base64.b64encode(qr_image_data).decode("utf-8")
                st.image(f"data:image/png;base64,{b64_img}", width=300)
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°äºŒç»´ç å›¾ç‰‡")

        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½äºŒç»´ç å¤±è´¥ï¼š{e}")

    # ç§»åŠ¨ç«¯é€‚é…
    st.markdown(
        """
        <script>
            window.addEventListener('resize', function() {
                const images = document.querySelectorAll('img');
                images.forEach(img => {
                    if(window.innerWidth < 768) {
                        img.style.maxHeight = '200px';
                    } else {
                        img.style.maxHeight = 'none';
                    }
                });
            });
        </script>
    """,
        unsafe_allow_html=True,
    )


# ç®¡ç†å‘˜ä¸Šä¼ æ¨¡å—
def admin_upload_center():
    st.title("ğŸ“¤ ç®¡ç†å‘˜ä¸Šä¼ ä¸­å¿ƒ")
    st.caption("âš ï¸ ä»…é™æˆæƒäººå‘˜ä½¿ç”¨")
    st.markdown("---")

    password = st.text_input("ğŸ” è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")
    if password != "00277":
        st.warning("ğŸ”’ å¯†ç é”™è¯¯ï¼Œæ— æ³•è®¿é—®ä¸Šä¼ åŠŸèƒ½")
        return

    category = st.selectbox("ğŸ“ ä¸Šä¼ ç›®å½•", ["è¡Œæµ‹", "ç”³è®º", "è§†é¢‘", "é«˜åˆ†ç»éªŒ", "æ”¿ç­–å’¨è¯¢", "è€ƒè¯•æ—¥å†"])
    files = st.file_uploader("ğŸ“ é€‰æ‹©æ–‡ä»¶", accept_multiple_files=True)
    if st.button("ğŸš€ ä¸Šä¼ æ–‡ä»¶"):
        with st.spinner("ğŸ“¤ æ­£åœ¨ä¸Šä¼ ä¸­..."):
            for file in files:
                upload_file_to_oss(file, category=category)
        st.success("âœ… ä¸Šä¼ å®Œæˆï¼")


# ä¸»å‡½æ•°
def main():
    dark_mode = st.sidebar.toggle("ğŸŒ™ å¤œé—´æ¨¡å¼")
    set_dark_mode(dark_mode)

    st.sidebar.title("ğŸ¯ å…¬è€ƒåŠ©æ‰‹")
    menu = st.sidebar.radio(
        "ğŸ“Œ åŠŸèƒ½å¯¼èˆª", ["æ™ºèƒ½é—®ç­”", "è€ƒè¯•æ—¥å†", "å¤‡è€ƒèµ„æ–™", "æ”¿ç­–èµ„è®¯", "é«˜åˆ†ç»éªŒ", "ä¸Šä¼ èµ„æ–™ï¼ˆç®¡ç†å‘˜ï¼‰"]
    )

    if menu == "æ™ºèƒ½é—®ç­”":
        showLLMChatbot()
    elif menu == "è€ƒè¯•æ—¥å†":
        display_exam_calendar()
    elif menu == "å¤‡è€ƒèµ„æ–™":
        display_study_materials()
    elif menu == "æ”¿ç­–èµ„è®¯":
        display_policy_news()
    elif menu == "é«˜åˆ†ç»éªŒ":
        display_experience()
    elif menu == "ä¸Šä¼ èµ„æ–™ï¼ˆç®¡ç†å‘˜ï¼‰":
        admin_upload_center()


if __name__ == "__main__":
    main()
