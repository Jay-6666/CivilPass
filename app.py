import streamlit as st
import openai
import oss2
import time
import pandas as pd
from io import BytesIO
from dotenv import load_dotenv
import os

# ========== åŠ è½½ç¯å¢ƒå˜é‡ ==========
load_dotenv()

ACCESS_KEY_ID = os.getenv("ACCESS_KEY_ID")
ACCESS_KEY_SECRET = os.getenv("ACCESS_KEY_SECRET")
BUCKET_NAME = os.getenv("BUCKET_NAME")
REGION = os.getenv("REGION")
API_KEY = os.getenv("API_KEY")

ENDPOINT = f"https://{BUCKET_NAME}.oss-{REGION}.aliyuncs.com"

# ========== é…ç½®é˜¿é‡Œäº‘ OSS ==========
auth = oss2.Auth(ACCESS_KEY_ID, ACCESS_KEY_SECRET)
bucket = oss2.Bucket(auth, f"http://oss-{REGION}.aliyuncs.com", BUCKET_NAME)

# ========== ä¸Šä¼ å›¾ç‰‡åˆ° OSS ==========
def upload_image_to_oss(image_file):
    file_name = f"public/{int(time.time())}_{image_file.name}"
    bucket.put_object(file_name, image_file.getvalue())
    oss_url = f"{ENDPOINT}/{file_name}"
    return oss_url

# ========== è°ƒç”¨å¤§æ¨¡å‹ ==========
def query_qwen_api(user_input, image_url=None):
    client = openai.OpenAI(api_key=API_KEY, base_url=BASE_URL)
    messages = [{"role": "user", "content": []}]
    if user_input:
        messages[0]["content"].append({"type": "text", "text": user_input})
    if image_url:
        messages[0]["content"].append({"type": "image_url", "image_url": {"url": image_url}})
    try:
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"âŒ AI è§£æå¤±è´¥: {str(e)}"

# ========== æ™ºèƒ½é—®ç­”æ¨¡å— ==========
def showLLMChatbot():
    st.title("ğŸ“ æ™ºèƒ½å…¬è€ƒåŠ©æ‰‹")
    st.caption("ğŸ“¢ è¾“å…¥ä½ çš„å…¬è€ƒé—®é¢˜ï¼Œæˆ–ä¸Šä¼ è¯•é¢˜æˆªå›¾ï¼ŒAI å¸®ä½ è§£ç­”ï¼")
    question_type = st.selectbox("ğŸ” é€‰æ‹©é—®é¢˜ç±»å‹", ["æ™®é€šé—®é¢˜", "å®šä¹‰é—®é¢˜", "è§£é‡Šé—®é¢˜", "å†å²é—®é¢˜"])
    info = st.text_input("âœï¸ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
    uploaded_file = st.file_uploader("ğŸ“· ä¸Šä¼ è¯•é¢˜æˆªå›¾ï¼ˆæ”¯æŒ JPG/PNGï¼‰", type=["jpg", "png", "jpeg"])
    image_url = None
    if uploaded_file:
        st.image(uploaded_file, caption="å·²ä¸Šä¼ çš„è¯•é¢˜æˆªå›¾", use_container_width=True)
        with st.spinner("ğŸ”„ æ­£åœ¨ä¸Šä¼ å›¾ç‰‡..."):
            image_url = upload_image_to_oss(uploaded_file)
        st.success(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼URL: {image_url}")
    if st.button("ğŸ¤– è·å–ç­”æ¡ˆ"):
        if not info and not image_url:
            st.warning("âš ï¸ è¯·è¾“å…¥é—®é¢˜æˆ–ä¸Šä¼ è¯•é¢˜å›¾ç‰‡ï¼")
        else:
            st.write(f"ğŸ“¢ **ä½ é—®:** {info if info else 'ï¼ˆä»…ä¸Šä¼ å›¾ç‰‡ï¼‰'}")
            answer = query_qwen_api(info, image_url)
            st.success("âœ… AI è§£æç»“æœï¼š")
            st.write(answer)

# ========== å¤‡è€ƒèµ„æ–™æ¨¡å— ==========
def display_study_materials():
    st.title("ğŸ“š å¤‡è€ƒèµ„æ–™")
    st.caption("ğŸ“¢ æä¾›å„ç±»å¤‡è€ƒèµ„æ–™ï¼Œæ”¯æŒä¸‹è½½å’Œåœ¨çº¿æ’­æ”¾è§†é¢‘ï¼")
    categories = ["è¡Œæµ‹", "ç”³è®º", "è§†é¢‘"]
    selected_categories = st.multiselect("é€‰æ‹©å¤‡è€ƒèµ„æ–™ç±»å‹", categories)
    if selected_categories:
        for category in selected_categories:
            st.header(f"ğŸ“‚ {category} ç±»åˆ«")
            result = bucket.list_objects(prefix=category)
            if result.object_list:
                for obj in result.object_list:
                    file_url = f"{ENDPOINT}/{obj.key}"
                    file_name = obj.key.split("/")[-1].lower()
                    if file_name.endswith((".mp4", ".mov", ".avi", ".webm")):
                        st.markdown(f"ğŸ¬ **{obj.key}**")
                        st.video(file_url)
                        st.markdown(f"[ä¸‹è½½è§†é¢‘]({file_url})")
                    elif file_name.endswith(".pdf"):
                        st.markdown(f"ğŸ“„ **{obj.key}**")
                        st.components.v1.iframe(file_url, height=600, scrolling=True)
                        st.markdown(f"[ç‚¹å‡»ä¸‹è½½]({file_url})")
                    else:
                        st.markdown(f"ğŸ“„ **{obj.key}**")
                        st.markdown(f"[ç‚¹å‡»ä¸‹è½½]({file_url})")
                    st.markdown("---")
            else:
                st.warning(f"æ²¡æœ‰æ‰¾åˆ° {category} ç±»åˆ«çš„èµ„æ–™ã€‚")
    else:
        st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªå¤‡è€ƒèµ„æ–™ç±»åˆ«ã€‚")

# ========== é«˜åˆ†ç»éªŒæ¨¡å— ==========
def display_experience():
    st.title("ğŸŒŸ é«˜åˆ†ç»éªŒ")
    st.caption("ğŸ“¢ æ¥è‡ªé«˜åˆ†è€ƒç”Ÿçš„åˆ†äº«èµ„æ–™ï¼Œæ”¯æŒåœ¨çº¿é¢„è§ˆï¼")
    result = bucket.list_objects(prefix="é«˜åˆ†ç»éªŒ/")
    if result.object_list:
        for obj in result.object_list:
            if obj.key.endswith(".pdf"):
                file_url = f"{ENDPOINT}/{obj.key}"
                st.markdown(f"ğŸ“„ **{obj.key.split('/')[-1]}**")
                st.components.v1.iframe(file_url, height=600, scrolling=True)
                st.markdown(f"[ç‚¹å‡»ä¸‹è½½]({file_url})")
                st.markdown("---")
    else:
        st.warning("ğŸ˜¢ æš‚æ— é«˜åˆ†ç»éªŒèµ„æ–™ã€‚")

# ========== æ”¿ç­–èµ„è®¯æ¨¡å— ==========
def display_policy_news():
    st.title("ğŸ“° æ”¿ç­–èµ„è®¯")
    st.caption("ğŸ“¢ æœ€æ–°å…¬åŠ¡å‘˜æ”¿ç­–ã€å…¬å‘Šä¿¡æ¯ä¸€ç½‘æ‰“å°½")
    csv_key = "æ”¿ç­–å’¨è¯¢/civilpass_data.csv"
    try:
        csv_data = bucket.get_object(csv_key)
        df = pd.read_csv(BytesIO(csv_data.read()), encoding="utf-8")

        if df.shape[1] == 1:
            df.columns = ['url']
            df['title'] = [f"æ”¿ç­–èµ„è®¯ç¬¬{i+1}æ¡" for i in range(len(df))]
            df['source'] = 'æœªçŸ¥æ¥æº'
            df['date'] = 'æ— '
        elif not {"title", "source", "date", "url"}.issubset(df.columns):
            st.error("âŒ CSV æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼štitle, source, date, url")
            return

        df['date'] = pd.to_datetime(df['date'], errors='coerce')

        with st.expander("ğŸ” ç­›é€‰åŠŸèƒ½"):
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input("ğŸ“… èµ·å§‹æ—¥æœŸ", pd.to_datetime("2024-01-01"))
            with col2:
                end_date = st.date_input("ğŸ“… æˆªæ­¢æ—¥æœŸ", pd.to_datetime("today"))

            keyword = st.text_input("ğŸ” è¾“å…¥å…³é”®è¯ï¼ˆæ”¯æŒæ ‡é¢˜/æ¥æºæœç´¢ï¼‰")

        filtered_df = df.copy()
        if not df['date'].isna().all():
            filtered_df = filtered_df[(filtered_df['date'] >= pd.to_datetime(start_date)) &
                                      (filtered_df['date'] <= pd.to_datetime(end_date))]
        if keyword:
            keyword_lower = keyword.lower()
            filtered_df = filtered_df[
                filtered_df['title'].str.lower().str.contains(keyword_lower, na=False) |
                filtered_df['source'].str.lower().str.contains(keyword_lower, na=False)
            ]

        if not filtered_df.empty:
            for _, row in filtered_df.sort_values(by="date", ascending=False).head(30).iterrows():
                st.markdown(f"### ğŸ”— [{row['title']}]({row['url']})")
                st.markdown(f"ğŸ“… æ—¥æœŸ: {row['date'].date() if pd.notna(row['date']) else 'æ— '} | ğŸ› æ¥æº: {row['source']}")
                st.markdown("---")
        else:
            st.warning("ğŸ˜¢ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ”¿ç­–èµ„è®¯ï¼Œè¯·è°ƒæ•´å…³é”®è¯æˆ–æ—¥æœŸèŒƒå›´ã€‚")

    except oss2.exceptions.NoSuchKey:
        st.error("âŒ æœªæ‰¾åˆ°æ”¿ç­–èµ„è®¯æ–‡ä»¶ civilpass_data.csv")
    except Exception as e:
        st.error(f"âŒ åŠ è½½æ”¿ç­–èµ„è®¯å¤±è´¥ï¼š{str(e)}")

# ========== è€ƒè¯•æ—¥å†æ¨¡å— ==========
def display_exam_calendar():
    st.title("ğŸ“… è€ƒè¯•æ—¥å†")
    st.markdown("### âš ï¸ <span style='color:red;font-weight:bold;'>è€ƒè¯•æ—¶é—´ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®˜æ–¹å…¬å¸ƒä¸ºå‡†ï¼</span>", unsafe_allow_html=True)

    try:
        result = bucket.list_objects(prefix="è€ƒè¯•æ—¥å†/")
        if result.object_list:
            # ä¸­æ–‡æœˆä»½æ˜ å°„è¡¨
            month_mapping = {
                "ä¸€æœˆ": 1, "äºŒæœˆ": 2, "ä¸‰æœˆ": 3, "å››æœˆ": 4,
                "äº”æœˆ": 5, "å…­æœˆ": 6, "ä¸ƒæœˆ": 7, "å…«æœˆ": 8,
                "ä¹æœˆ": 9, "åæœˆ": 10, "åä¸€æœˆ": 11, "åäºŒæœˆ": 12
            }

            # æå–ä¸­æ–‡æœˆä»½æ ‡ç­¾å¹¶æ’åº
            def extract_month_index(filename):
                name = filename.split("/")[-1]  # è·å–æ–‡ä»¶å
                for month_name, idx in month_mapping.items():
                    if name.startswith(month_name):  # ç¡®ä¿æ˜¯å‰ç¼€åŒ¹é…ï¼Œé˜²æ­¢"åä¸€æœˆ"åŒ¹é…"ä¸€æœˆ"
                        return idx
                return 999  # æ²¡åŒ¹é…çš„æ”¾æœ€å

            # æ’åº
            sorted_images = sorted(
                [obj for obj in result.object_list if obj.key.lower().endswith((".jpg", ".png", ".jpeg"))],
                key=lambda obj: extract_month_index(obj.key)
            )

            # å±•ç¤ºå›¾ç‰‡
            for obj in sorted_images:
                img_url = f"{ENDPOINT}/{obj.key}"
                st.image(img_url, caption=obj.key.split("/")[-1], use_container_width=True)
                st.markdown("---")
        else:
            st.warning("ğŸ˜¢ OSS ä¸­æ²¡æœ‰è€ƒè¯•æ—¥å†å›¾ç‰‡ã€‚")
    except Exception as e:
        st.error(f"âŒ è¯»å–è€ƒè¯•æ—¥å†å¤±è´¥ï¼š{str(e)}")



# ========== ä¸»å‡½æ•° ==========
def main():
    st.sidebar.title("ğŸ¯ å…¬è€ƒåŠ©æ‰‹")
    menu = st.sidebar.radio("ğŸ“Œ é€‰æ‹©åŠŸèƒ½", ["æ™ºèƒ½é—®ç­”", "è€ƒè¯•æ—¥å†", "å¤‡è€ƒèµ„æ–™", "æ”¿ç­–èµ„è®¯", "é«˜åˆ†ç»éªŒ"])
    if menu == "æ™ºèƒ½é—®ç­”":
        showLLMChatbot()
    elif menu == "è€ƒè¯•æ—¥å†":
        display_exam_calendar()
    elif menu == "å¤‡è€ƒèµ„æ–™":
        display_study_materials()
    elif menu == "æ”¿ç­–èµ„è®¯":
        display_policy_news()
    elif menu == "é«˜åˆ†ç»éªŒ":
        display_experience()

# ========== å¯åŠ¨åº”ç”¨ ==========
if __name__ == '__main__':
    main()